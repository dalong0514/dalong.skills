<!-- 此文件由机器翻译自 knowledge_graphs.md -->

# 知识图谱推理

## 概述

知识图将结构化信息表示为图形格式的实体和关系。 TorchDrug 使用基于嵌入的模型和神经推理方法为知识图补全（链接预测）提供全面支持。

## 可用数据集

### 一般知识图

**FB15k（Freebase 子集）：**
- 14,951 个实体
- 1,345 种关系类型
- 592,213 个三元组
- 来自 Freebase 的一般世界知识

**FB15k-237：**
- 14,541 个实体
- 237 种关系类型
- 310,116 个三元组
- 过滤版本消除逆关系
- 更具挑战性的基准

**WN18（WordNet）：**
- 40,943 个实体（词义）
- 18 种关系类型（词汇关系）
- 151,442 个三元组
- 语言知识图谱

**WN18RR：**
- 40,943 个实体
- 11 种关系类型
- 93,003 个三元组
- 过滤 WordNet 去除简单的逆模式

### 生物医学知识图谱

**Hetionet：**
- 45,158 个实体（基因、化合物、疾病、途径等）
- 24 种关系类型（治疗、原因、绑定等）
- 2,250,197 条边
- 整合29个公共生物医学数据库
- 专为药物再利用和疾病了解而设计

## 任务：KnowledgeGraphCompletion

知识图的主要任务是链接预测 - 给定头实体和关系，预测尾实体（反之亦然）。

### 任务模式

**头部预测：**
- 给定（？，关系，尾部），预测头实体
- “什么会导致 X 病？”

**尾部预测：**
- 给定（头，关系，？），预测尾实体
- “X基因会引起什么疾病？”

**两者：**
- 预测头部和尾部
- 标准评估协议

### 评估指标

**排名指标：**
- **平均排名（MR）**：正确实体的平均排名
- **平均倒数排名 (MRR)**：1/排名的平均值
- **Hits@K**：前 K 个预测中正确实体的百分比
  - 通常报告为 K=1、3、10

**过滤与原始：**
- **过滤**：从排名中删除其他已知的真实三元组
- **原始**：在所有可能的实体中排名
- 过滤是评估标准

## 嵌入模型

### 转化模型

**TransE（翻译嵌入）：**
- 将关系表示为嵌入空间中的翻译
- h + r ≈ t （头 + 关系 ≈ 尾）
- 简单有效的基线
- 适合一对一关系
- 与N对N关系的斗争

**RotatE（旋转嵌入）：**
- 复杂空间中的旋转关系
- 更好地处理对称和逆关系
- 在许多基准上都是最先进的
- 可以对构图模式进行建模

### 语义匹配模型

**DistMult：**
- 双线性评分函数
- 自然地处理对称关系
- 无法模拟不对称关系
- 速度快且内存效率高

**复杂：**
- 复值嵌入
- 建立不对称和逆关系模型
- 对于大多数图表来说比 DistMult 更好
- 平衡表现力和效率

**简单：**
- 使用逆关系扩展 DistMult
- 充分表达（可以表示任何关系模式）
- 每个实体有两个嵌入（规范和逆）

### 神经逻辑模型

**NeuralLP（神经逻辑编程）：**
- 通过可微分运算学习逻辑规则
- 通过学习的规则解释预测
- 适合稀疏知识图
- 计算成本更高

**KBGAT（知识库图注意力）：**
- 用于 KG 补全的图注意力网络
- 从邻域学习实体表示
- 通过归纳学习处理看不见的实体
- 更适合不完整的图表

## 培训工作流程

### 基本管道

```python
from torchdrug import datasets, models, tasks, core

# Load dataset
dataset = datasets.FB15k237("~/kg-datasets/")

# Define model
model = models.RotatE(
    num_entity=dataset.num_entity,
    num_relation=dataset.num_relation,
    embedding_dim=2000,
    max_score=9
)

# Define task
task = tasks.KnowledgeGraphCompletion(
    model,
    num_negative=128,
    adversarial_temperature=2,
    criterion="bce"
)

# Train with PyTorch Lightning or custom loop
```

### 负采样

**策略：**
- **均匀**：随机均匀采样实体
- **自我对抗**：根据当前模型的分数对样本进行加权
- **类型约束**：仅对关系的有效实体类型进行采样

**参数：**
- `num_negative`：每个正三元组的负样本数
- `adversarial_temperature`：自我对抗权重的温度
- 更高的温度=更多地关注硬底片

### 损失函数

**二元交叉熵 (BCE)：**
- 独立对待每个三元组
- 积极和消极之间的平衡分类

**保证金损失：**
- 确保正分明显高于负分
- `max(0, margin + score_neg - score_pos)`

**物流损失：**
- 保证金损失的平滑版本
- 更好的渐变特性

## 选型指南

### 按关系模式

**一对一关系：**
- TransE 效果很好
- 任何模式都有可能成功

**一对多关系：**
- DistMult、ComplEx、SimplE
- 避免 TransE
**N 对 1 关系：**
- DistMult、ComplEx、SimplE
- 避免 TransE

**N对N关系：**
- 复杂、简单、旋转
- 最具挑战性的模式

**对称关系：**
- DistMult，复杂
- RotatE 进行正确的初始化

**反对称关系：**
- 复杂、简单、旋转
- 避免 DistMult

**逆关系：**
- 复杂、简单、旋转
- 对于双向推理很重要

**成分：**
- RotatE（最佳）
- TransE（合理）
- 捕获多跳路径

### 按数据集特征

**小图（< 50k 实体）：**
- 复杂或简单
- 较低的嵌入尺寸 (200-500)

**大型图（> 100k 个实体）：**
- DistMult 提高效率
- 旋转以确保准确性
- 更高的维度（500-2000）

**稀疏图：**
- NeuralLP（从有限数据中学习规则）
- 在较大的图上预训练嵌入

**密集、完整的图表：**
- 任何嵌入模型都可以很好地工作
- 根据关系模式进行选择

**生物医学/领域图：**
- 考虑采样中的类型约束
- 使用特定领域的负采样
- Hetionet 受益于特定于关系的模型

## 先进技术

### 多跳推理

链接多个关系来回答复杂的查询：
- “什么药物可以治疗 X 基因引起的疾病？”
- 需要基于路径或基于规则的推理
- NeuralLP 自然支持这一点

### 时态知识图

扩展到随时间变化的事实：
- 将时间信息添加到三元组
- 预测未来的事实
- 需要模型中的时间编码

### 少样本学习

用几个例子来处理关系：
- 元学习方法
- 相关关系转入
- 对于新兴知识很重要

### 归纳学习

推广到看不见的实体：
- KBGAT 和其他基于 GNN 的方法
- 使用实体特征/描述
- 对于不断发展的知识图谱至关重要

## 生物医学应用

### 药物再利用

预测 Hetionet 中的“药物治疗疾病”链接：
1. 对已知的药物-疾病协会进行培训
2. 预测新的治疗候选者
3. 按机制过滤（基因、通路参与）
4. 通过实验验证预测

### 疾病基因发现

识别与疾病相关的基因：
1. 基因-疾病-通路网络模型
2. 预测缺失的基因与疾病的联系
3. 纳入蛋白质相互作用、表达数据
4. 优先考虑候选人进行验证

### 蛋白质功能预测

将蛋白质与生物过程联系起来：
1. 整合蛋白质相互作用、GO术语
2. 预测缺失的GO注释
3. 相似蛋白质的传递函数

## 常见问题及解决方案

**问题：特定关系类型的性能不佳**
- 解决方案：分析关系模式，选择合适的模型，或使用特定于关系的模型

**问题：小图上的过度拟合**
- 解决方案：减少嵌入维数，增加正则化，或者使用更简单的模型

**问题：大图训练缓慢**
- 解决方案：减少负样本，使用DistMult提高效率，或者实施mini-batch训练

**问题：无法处理新实体**
- 解决方案：使用归纳模型（KBGAT），合并实体特征，或根据邻居预先计算新实体的嵌入

## 最佳实践

1. 对于大多数任务，从 ComplEx 或 RotatE 开始
2. 使用自我对抗负采样
3.调整嵌入维度（通常为500-2000）
4.应用正则化来防止过度拟合
5.使用过滤后的评估指标
6. 分析每种关系类型的性能
7. 考虑异构图的关系特定模型
8. 与领域专家验证预测