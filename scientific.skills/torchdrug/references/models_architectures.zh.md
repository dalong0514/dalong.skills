<!-- 此文件由机器翻译自 models_architectures.md -->

# 模型和架构

## 概述

TorchDrug 为各种基于图形的学习任务提供了全面的预构建模型架构集合。该参考对所有可用模型及其特征、用例和实现细节进行了分类。

## 图神经网络

### GCN（图卷积网络）

**类型：** 空间消息传递
**论文：** 使用图卷积网络进行半监督分类（Kipf & Welling，2017）

**特点：**
- 简单高效的聚合
- 归一化邻接矩阵卷积
- 适用于同质图
- 许多任务的良好基线

**最适合：**
- 初始实验和基线
- 当计算效率很重要时
- 具有清晰局部结构的图表

**参数：**
- `input_dim`：节点特征维度
- `hidden_dims`：隐藏层维度列表
- `edge_input_dim`：边缘特征尺寸（可选）
- `batch_norm`：应用批量归一化
- `activation`：激活函数（relu、elu 等）
- `dropout`：辍学率

**使用案例：**
- 分子性质预测
- 引文网络分类
- 社交网络分析

### GAT（图注意力网络）

**类型：** 基于注意力的消息传递
**论文：** 图注意力网络（Veličković 等人，2018）

**特点：**
- 学习邻居的注意力权重
- 对不同邻居的重要性不同
- 多头注意力以保证鲁棒性
- 自然地处理不同的节点度数

**最适合：**
- 当邻居重要性不同时
- 异构图
- 可解释的预测

**参数：**
- `input_dim`、`hidden_dims`：标准尺寸
- `num_heads`：注意力头的数量
- `negative_slope`：LeakyReLU 斜率
- `concat`：连接或平均多头输出

**使用案例：**
- 蛋白质-蛋白质相互作用预测
- 关注反应位点的分子生成
- 具有关系重要性的知识图推理

### GIN（图同构网络）

**类型：** 最强大的消息传递
**论文：** 图神经网络有多强大？ （徐等人，2019）

**特点：**
- 理论上最具表现力的GNN架构
- 单射聚合函数
- 可以区分GCN无法区分的图结构
- 通常在分子任务中表现最佳

**最适合：**
- 分子性质预测（最先进）
- 需要结构性歧视的任务
- 图分类

**参数：**
- `input_dim`、`hidden_dims`：标准尺寸
- `edge_input_dim`：包括边缘特征
- `batch_norm`：通常使用 true
- `readout`：图池（“总和”、“平均值”、“最大值”）
- `eps`：可学习或固定的 epsilon

**使用案例：**
- 药物性质预测（BBBP、HIV等）
- 分子生成
- 反应预测

### RGCN（关系图卷积网络）

**类型：** 多关系消息传递
**论文：** 使用图卷积网络对关系数据进行建模（Schlichtkrull 等人，2018）

**特点：**
- 处理多种边缘/关系类型
- 特定于关系的权重矩阵
- 参数效率的基础分解
- 知识图谱必备

**最适合：**
- 知识图谱推理
- 异质分子图
- 多关系数据

**参数：**
- `num_relation`：关系类型的数量
- `hidden_dims`：层尺寸
- `num_bases`：基础分解（减少参数）

**使用案例：**
- 知识图谱补全
- 逆合成（不同的键类型）
- 蛋白质相互作用网络

### MPNN（消息传递神经网络）

**类型：** 通用消息传递框架
**论文：** 量子化学的神经消息传递（Gilmer 等人，2017）

**特点：**
- 灵活的消息和更新功能
- 消息计算中的边缘特征
- 节点隐藏状态的 GRU 更新
- 用于图形表示的 Set2Set 读数

**最适合：**
- 量子化学预测
- 具有重要边缘信息的任务
- 当节点状态经过多次迭代演变时

**参数：**
- `input_dim`、`hidden_dim`：特征尺寸
- `edge_input_dim`：边缘特征尺寸
- `num_layer`：消息传递迭代
- `num_mlp_layer`：消息函数中的 MLP 层

**使用案例：**
- QM9量子属性预测
- 分子动力学
- 3D 构象感知任务
### SchNet（连续滤波器卷积网络）

**类型：** 3D 几何感知卷积
**论文：** SchNet：连续滤波器卷积神经网络（Schütt 等人，2017）

**特点：**
- 在 3D 原子坐标上运行
- 连续滤波器卷积
- 旋转和平移不变
- 非常适合量子化学

**最适合：**
- 3D分子结构任务
- 量子特性预测
- 蛋白质结构分析
- 能量和力预测

**参数：**
- `input_dim`：原子特征
- `hidden_dims`：层尺寸
- `num_gaussian`：距离的 RBF 基函数
- `cutoff`：交互截止距离

**使用案例：**
- QM9属性预测
- 分子动力学模拟
- 蛋白质-配体与结构的结合
- 晶体特性预测

### ChebNet（切比雪夫谱 CNN）

**类型：** 谱卷积
**论文：** 图上的卷积神经网络（Defferrard 等人，2016）

**特点：**
- 谱图卷积
- 切比雪夫多项式近似
- 捕获全局图结构
- 计算效率高

**最适合：**
- 需要全局信息的任务
- 当拉普拉斯图提供信息时
- 理论分析

**参数：**
- `input_dim`、`hidden_dims`：尺寸
- `num_cheb`：切比雪夫多项式的阶数

**使用案例：**
- 引文网络分类
- 脑网络分析
- 图表上的信号处理

### NFP（神经指纹）

**类型：** 分子指纹学习
**论文：** 用于学习分子指纹的图上的卷积网络（Duvenaud 等人，2015）

**特点：**
- 学习可区分的分子指纹
- 手工指纹（ECFP）的替代方案
- 循环卷积，如 ECFP
- 可解释的学习特征

**最适合：**
- 分子相似性学习
- 有限数据下的房产预测
- 当可解释性很重要时

**参数：**
- `input_dim`、`output_dim`：特征尺寸
- `hidden_dims`：层尺寸
- `num_layer`：循环卷积深度

**使用案例：**
- 虚拟筛选
- 分子相似性搜索
- QSAR建模

## 蛋白质特异性模型

### GearNet（几何感知关系图网络）

**类型：** 蛋白质结构编码器
**论文：** 通过几何结构预训练进行蛋白质表示学习（Zhang 等人，2023）

**特点：**
- 包含 3D 几何信息
- 多种边缘类型（顺序、空间、KNN）
- 专为蛋白质设计
- 最先进的蛋白质任务

**最适合：**
- 蛋白质结构预测
- 蛋白质功能预测
- 蛋白质-蛋白质相互作用
- 任何涉及蛋白质 3D 结构的任务

**参数：**
- `input_dim`：剩余特征
- `hidden_dims`：层尺寸
- `num_relation`：边类型（序列、半径、KNN）
- `edge_input_dim`：几何特征（距离、角度）
- `batch_norm`：通常为真

**使用案例：**
- 酶功能预测（EnzymeCommission）
- 蛋白质折叠识别
- 接触预测
- 结合位点识别

### ESM（进化尺度建模）

**类型：** 蛋白质语言模型（变压器）
**论文：** 生物结构和功能源自扩展无监督学习（Rives 等人，2021）

**特点：**
- 经过 250M+ 蛋白质序列的预训练
- 捕获进化和结构信息
- 变压器架构
- 下游任务的迁移学习

**最适合：**
- 任何基于序列的蛋白质任务
- 当没有可用结构时
- 有限数据的迁移学习

**变体：**
- ESM-1b：650M参数
- ESM-2：多种尺寸（8M至15B参数）

**使用案例：**
- 蛋白质功能预测
- 变异效应预测
- 蛋白质设计
- 结构预测（ESMFold）

### 蛋白质BERT

**类型：** 蛋白质的屏蔽语言模型

**特点：**
- BERT式预训练
- 掩蔽氨基酸预测
- 双向上下文
- 适合基于序列的任务

**使用案例：**
- 函数注释
- 亚细胞定位
- 稳定性预测

### ProteinCNN / ProteinResNet

**类型：** 序列的卷积网络

**特点：**
- 序列上的一维卷积
- 本地模式识别
- 比变压器更快
- 适合主题检测

**使用案例：**
- 结合位点预测
- 二级结构预测
- 域名识别

### 蛋白质LSTM
**类型：** 序列的循环网络

**特点：**
- 双向LSTM
- 捕获远程依赖关系
- 顺序处理
- 序列任务的良好基线

**使用案例：**
- 订单预测
- 顺序注释
- 时间序列蛋白质数据

## 知识图模型

### TransE（翻译嵌入）

**类型：** 基于翻译的嵌入
**论文：** 翻译嵌入以建模多关系数据（Bordes 等人，2013 年）

**特点：**
- h + r ≈ t （头 + 关系 ≈ 尾）
- 简单且可解释
- 适合一对一关系
- 内存高效

**最适合：**
- 大知识图谱
- 初步实验
- 可解释的嵌入

**参数：**
- `num_entity`、`num_relation`：图形大小
- `embedding_dim`：嵌入尺寸（通常为 50-500）

### RotatE（旋转嵌入）

**类型：** 复杂空间中的旋转
**论文：** RotatE：复杂空间中关系旋转的知识图嵌入（Sun 等人，2019）

**特点：**
- 复杂空间中的旋转关系
- 处理对称、反对称、逆、合成
- 在许多基准上都是最先进的

**最适合：**
- 大多数知识图谱任务
- 复杂的关系模式
- 当准确性至关重要时

**参数：**
- `num_entity`、`num_relation`：图形大小
- `embedding_dim`：必须是偶数（复杂嵌入）
- `max_score`：分数裁剪值

### DistMult

**类型：** 双线性模型

**特点：**
- 对称关系建模
- 快速高效
- 无法模拟反对称关系

**最适合：**
- 对称关系（例如“类似于”）
- 当速度至关重要时
- 大比例图表

### 复杂

**类型：** 复值嵌入

**特点：**
- 处理不对称和对称关系
- 对于大多数图表来说比 DistMult 更好
- 表现力和效率的良好平衡

**最适合：**
- 一般知识图谱补全
- 混合关系类型
- 当 RotatE 过于复杂时

### 简单

**类型：** 增强嵌入模型

**特点：**
- 每个实体有两个嵌入（规范+逆向）
- 充分表达
- 参数比 ComplEx 稍多

**最适合：**
- 当需要充分表达时
- 逆关系很重要

## 生成模型

### 图自回归流

**类型：** 分子标准化流动

**特点：**
- 精确的似然计算
- 可逆变换
- 稳定的训练（无对抗性）
- 有条件的生成支持

**最适合：**
- 分子生成
- 密度估计
- 分子之间的插值

**参数：**
- `input_dim`：原子特征
- `hidden_dims`：耦合层
- `num_flow`：流转换的数量

**使用案例：**
- 从头药物设计
- 化学空间探索
- 以财产为目标的一代

## 预训练模型

### 信息图

**类型：** 对比学习

**特点：**
- 最大化相互信息
- 图级和节点级对比
- 无监督预训练
- 适用于小型数据集

**使用案例：**
- 预训练分子编码器
- 少样本学习
- 迁移学习

### 多视图对比

**类型：** 蛋白质多视图对比学习

**特点：**
- 对比蛋白质的不同观点
- 几何预训练
- 使用 3D 结构信息
- 非常适合蛋白质模型

**使用案例：**
- 在蛋白质结构上预训练 GearNet
- 转移到财产预测
- 有限的标记数据场景

## 选型指南

### 按任务类型

**分子性质预测：**
1.GIN（首选）
2.GAT（可解释性）
3.SchNet（3D可用）

**蛋白质任务：**
1. ESM（仅序列）
2. GearNet（结构可用）
3. ProteinBERT（序列，比ESM更轻）

**知识图谱：**
1.RotatE（最佳性能）
2.ComplEx（良好的平衡）
3. TransE（大图，高效）

**分子生成：**
1.GraphAutoregressiveFlow（精确似然）
2. 带有GIN主干的GCPN（属性优化）

**逆合成：**
1.GIN（合成器完成）
2. RGCN（带债券类型的中心标识）

### 按数据集大小

**小（< 1k）：**
- 使用预先训练的模型（蛋白质的 ESM）
- 更简单的架构（GCN、ProteinCNN）
- 重度正则化

**中（1k-100k）：**
- GIN 代表分子
- GAT 的可解释性
- 标准培训

**大（> 100k）：**
- 任何型号都可以
- 更深层次的架构
- 可以从头开始训练

### 按计算预算

**低：**
- GCN（最简单）
- 距离 (公斤)
- 蛋白质LSTM

**中：**
-杜松子酒
- 盖特
- 复杂

**高：**
- ESM（大）
- SchNet (3D)
- RotatE 高亮度

## 实施技巧

1. **从简单开始**：从 GCN 或 GIN 基线开始
2. **使用预训练**：ESM 用于蛋白质，InfoGraph 用于分子
3. **调整深度**：3-5 层通常就足够了
4. **批量归一化**：通常有帮助（KG 嵌入除外）
5. **剩余连接**：对于深度网络很重要
6. **读出功能**：“mean”通常效果很好
7. **边缘特征**：包括（如果可用）（键、距离）
8. **正则化**：Dropout、权重衰减、早期停止