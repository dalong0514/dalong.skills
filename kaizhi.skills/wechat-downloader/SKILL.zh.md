---
name: wechat-downloader
description: 高性能批量下载微信公众号文章,支持并行处理、智能重试和全面错误处理。当用户需要批量备份、归档或迁移微信公众号文章时使用此技能,提供高效的并行下载、进度跟踪和失败恢复功能。
---

# 微信文章下载器

批量下载微信公众号文章,具有高性能并行处理、智能错误处理和全面进度跟踪功能。

## 何时使用此技能

当用户需要以下功能时使用此技能:
- 备份微信公众号文章供离线阅读
- 归档关注账号的内容
- 将微信内容迁移到个人博客或知识库
- 收集文章进行数据分析或研究
- 高效下载大量文章(10篇以上)

## 核心功能

### 1. 高性能并行下载
- 多线程并发下载(默认: 20线程)
- 连接池复用优化网络性能
- 根据网络状况可配置并发数
- 平均速度: 典型场景下1.0篇/秒

### 2. 智能错误处理
- 自动分类失败类型:
  - 已删除/违规文章
  - 网络超时
  - 连接错误
- 智能重试机制,指数退避
- 详细失败报告,分类原因

### 3. 进度跟踪
- 实时进度条显示完成百分比
- 实时成功率计算
- 预计剩余时间
- 完成后详细统计

### 4. 断点续传
- 跳过已下载文件(恢复中断的下载)
- 单独的重试脚本处理失败文章
- 跨会话维护下载状态

## 使用流程

### 步骤 1: 准备文章列表

用户需要提供包含文章列表的 JSON 文件,格式如下:

```json
{
  "export_time": "2025-11-29T10:06:06.152Z",
  "total_count": 354,
  "articles": [
    {
      "title": "文章标题",
      "url": "https://mp.weixin.qq.com/s/xxxxx",
      "content_url": "https://mp.weixin.qq.com/s/xxxxx",
      "digest": "文章摘要",
      "author": "作者名称",
      "publish_date": "2025-01-01"
    }
  ]
}
```

如果用户没有此 JSON 文件,提供浏览器控制台脚本(位于 `references/export_script.js`)从微信网页界面导出文章列表。

### 步骤 2: 下载文章

使用主下载脚本(`scripts/download_articles.py`)执行批量下载:

```bash
uv run scripts/download_articles.py
```

脚本将:
1. 从 JSON 读取文章列表
2. 为下载的文章创建输出目录
3. 使用 20 个并行线程下载文章
4. 使用 tqdm 显示实时进度
5. 将成功下载保存为带元数据的 HTML 文件
6. 为任何不成功的下载生成失败报告

### 步骤 3: 处理失败(如需要)

如果有下载失败,使用重试脚本(`scripts/retry_failed.py`):
- 使用更长超时重新尝试下载
- 验证文章是否真的已删除/不可用
- 提供详细的失败分类
- 更新失败列表

```bash
uv run scripts/retry_failed.py
```

### 步骤 4: 验证结果

检查下载统计:
- 成功率(目标: >95%)
- 下载文章总数
- 分类的失败原因
- 平均下载速度

## 性能优化

### 基于网络的调优

根据网络条件调整 `max_workers` 参数:

**高速网络(100Mbps+)**:
```python
max_workers = 30
timeout = 10
```

**中速网络(10-100Mbps)**:
```python
max_workers = 15  # 默认值
timeout = 15
```

**低速网络(<10Mbps)**:
```python
max_workers = 5
timeout = 30
max_retries = 3
```

### 配置参数

脚本中可调整的关键参数:

- `max_workers`: 并发下载线程数(5-30)
- `timeout`: 请求超时秒数(10-30)
- `max_retries`: 每篇文章最大重试次数(2-5)
- `retry_delay`: 重试间隔秒数(0.5-2.0)
- `pool_connections`: HTTP 连接池大小(匹配 max_workers)

## 输出结构

```
output_directory/
├── 0001_文章标题.html
├── 0002_文章标题.html
├── ...
├── failed_articles.json      # 失败下载列表
└── retry_results.json        # 重试尝试结果
```

每个 HTML 文件包含:
- 文章内容
- 元数据注释(标题、URL、下载时间)
- 原始格式和图片

## 错误分类

技能将失败分为不同类型:

**🗑️ 已删除/违规文章**
- 发布者删除文章
- 内容违反平台规则
- 文章被举报下架
- **措施**: 无法进一步操作

**⏱️ 网络超时**
- 请求超过超时限制
- 服务器响应慢
- 网络不稳定
- **措施**: 使用更长超时重试

**❌ 其他错误**
- 连接被拒绝
- 无效 URL
- 文件系统错误
- **措施**: 调查具体错误消息

## 最佳实践

### 开始前
1. 验证 JSON 文件格式和内容
2. 检查可用磁盘空间(估计: 每篇约50KB)
3. 确保网络连接稳定
4. 先用小批量测试(10-20篇文章)

### 下载期间
1. 监控进度条异常
2. 检查成功率(应该>90%)
3. 不要中断进程
4. 注意系统资源问题

### 下载后
1. 审查成功率和失败原因
2. 对超时失败运行重试脚本
3. 验证随机抽样的下载文章
4. 备份下载内容
5. 清理旧文章列表和失败文章

### 性能提示
1. 从默认设置开始(20线程)
2. 根据观察到的性能调整
3. 避免在高峰时段下载
4. 大批量使用有线连接
5. 关闭不必要的应用程序释放资源

## 故障排除

### 高失败率(>10%)
- 减少 `max_workers` 到 10
- 增加 `timeout` 到 25
- 检查网络稳定性
- 验证 JSON 文件 URL 有效

### 下载速度慢(<0.5篇/秒)
- 增加 `max_workers` 到 25-30
- 检查网络带宽使用
- 验证微信无速率限制
- 考虑时间(避免高峰时段)

### 内存问题
- 减少 `max_workers` 到 5-10
- 按100篇文章批量处理
- 清除浏览器缓存并关闭其他应用
- 确保有足够 RAM 可用

### 文件系统错误
- 检查磁盘空间
- 验证写入权限
- 确保文件名有效
- 检查路径长度限制

## 高级用法

### 批量处理多个账号
按顺序处理多个 JSON 文件,带延迟:

```python
import time
import glob

for json_file in glob.glob('*.json'):
    process_articles(json_file)
    time.sleep(60)  # 账号间隔60秒
```

### 自定义输出格式
修改保存函数以导出不同格式(Markdown、PDF 等)。详见 `references/conversion_guide.md`。

### 与知识库集成
下载的文章可以集成到:
- Obsidian(转换为 Markdown)
- Notion(导入 HTML)
- Logseq(转换为 Markdown)
- 自定义知识管理系统

## 技术细节

### 依赖项
- Python 3.11+
- requests (HTTP 库)
- tqdm (进度条)
- uv (包管理器,使用 PEP 723 内联元数据)

### 实现亮点
- **会话复用**: 带连接池的 HTTP 会话提高性能
- **PEP 723 合规**: 内联脚本元数据管理依赖
- **Unicode 处理**: 中文内容正确 UTF-8 编码
- **文件名清理**: 自动清理非法字符
- **元数据保留**: HTML 注释中的文章信息

## 成功指标

预期性能基准:

| 指标 | 目标 | 优秀 |
|------|------|------|
| 成功率 | >90% | >95% |
| 下载速度 | >0.5/秒 | >1.0/秒 |
| 重试有效性 | >50% | >80% |
| 网络效率 | 稳定 | 最优 |

## 参考资料

详细实现指南,请查阅:
- `references/export_script.js` - 导出文章列表的浏览器控制台脚本
- `references/conversion_guide.md` - 将下载的 HTML 转换为其他格式
- `references/troubleshooting.md` - 详细故障排除场景

## 注意事项

- 遵守微信服务条款
- 仅用于个人备份,不得商业再分发
- 下载内容保留原始版权
- 注意服务器负载(避免过度并发请求)
- 某些文章可能因删除或违规而合法不可用
