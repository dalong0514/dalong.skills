#!/usr/bin/env python3
# /// script
# requires-python = ">=3.11"
# dependencies = [
#     "requests",
#     "tqdm",
# ]
# ///

"""
é‡æ–°æ ¸æŸ¥å¤±è´¥æ–‡ç« çš„è„šæœ¬

ä½¿ç”¨ 10 ä¸ªå¹¶å‘ä»»åŠ¡æ ¸æŸ¥å¤±è´¥çš„æ–‡ç« ,éªŒè¯æ˜¯å¦çœŸçš„å¤±è´¥ã€‚
"""

import json
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Dict, Tuple

import requests
from tqdm import tqdm


# å…¨å±€ä¼šè¯å¯¹è±¡
session = requests.Session()
session.mount('https://', requests.adapters.HTTPAdapter(
    pool_connections=10,
    pool_maxsize=10,
    max_retries=3
))


def sanitize_filename(filename: str, max_length: int = 100) -> str:
    """æ¸…ç†æ–‡ä»¶å"""
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    filename = filename.strip()
    if len(filename) > max_length:
        filename = filename[:max_length]
    return filename


def check_article(failed_item: Dict, articles: list, output_dir: Path) -> Tuple[str, str, str]:
    """
    æ ¸æŸ¥å•ç¯‡æ–‡ç« 

    Returns:
        (æ ‡é¢˜, çŠ¶æ€, è¯¦ç»†ä¿¡æ¯)
    """
    index = failed_item['index']
    title = failed_item['title']
    original_error = failed_item['error']

    # è·å–æ–‡ç« URL
    article = articles[index - 1]  # ç´¢å¼•ä»1å¼€å§‹,åˆ—è¡¨ä»0å¼€å§‹
    url = article.get('content_url') or article.get('url')

    if not url:
        return title, "âŒ å¤±è´¥", "ç¼ºå°‘URL"

    # æ£€æŸ¥æ˜¯å¦å·²ç»ä¸‹è½½æˆåŠŸ
    safe_title = sanitize_filename(title)
    filename = f"{index:04d}_{safe_title}.html"
    filepath = output_dir / filename

    if filepath.exists():
        return title, "âœ… å·²å­˜åœ¨", "æ–‡ä»¶å·²ä¸‹è½½"

    # è®¾ç½®è¯·æ±‚å¤´
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Connection': 'keep-alive',
    }

    # å°è¯•å¤šæ¬¡é‡è¯•(æœ€å¤š3æ¬¡)
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´è¿›è¡Œæ ¸æŸ¥
            response = session.get(url, headers=headers, timeout=30)
            response.raise_for_status()

            content = response.text

            # æ£€æŸ¥æ˜¯å¦æ˜¯è¢«åˆ é™¤çš„æ–‡ç« 
            if 'æ­¤å†…å®¹å› è¿è§„æ— æ³•æŸ¥çœ‹' in content:
                return title, "ğŸš« å·²è¿è§„", "å†…å®¹å› è¿è§„æ— æ³•æŸ¥çœ‹"

            if 'è¯¥å†…å®¹å·²è¢«å‘å¸ƒè€…åˆ é™¤' in content:
                return title, "ğŸ—‘ï¸  å·²åˆ é™¤", "å†…å®¹å·²è¢«å‘å¸ƒè€…åˆ é™¤"

            if 'è¯¥å†…å®¹å·²è¢«æŠ•è¯‰' in content:
                return title, "âš ï¸  å·²æŠ•è¯‰", "å†…å®¹å·²è¢«æŠ•è¯‰"

            if len(content) < 500:
                return title, "â“ å†…å®¹å¼‚å¸¸", f"å†…å®¹è¿‡çŸ­({len(content)}å­—ç¬¦)"

            # å¦‚æœå¯ä»¥æˆåŠŸä¸‹è½½,ä¿å­˜æ–‡ä»¶
            metadata = f"""<!--
æ–‡ç« æ ‡é¢˜: {title}
æ–‡ç« URL: {url}
ä¸‹è½½æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
é‡è¯•æ¬¡æ•°: {attempt + 1}
åŸé”™è¯¯: {original_error}
-->
"""
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(metadata + content)

            return title, "âœ… é‡è¯•æˆåŠŸ", f"ç¬¬{attempt + 1}æ¬¡é‡è¯•æˆåŠŸ"

        except requests.exceptions.Timeout:
            if attempt < max_retries - 1:
                time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                continue
            return title, "â±ï¸  è¶…æ—¶", f"å°è¯•{max_retries}æ¬¡åä»è¶…æ—¶"

        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                time.sleep(2)
                continue
            return title, "âŒ ç½‘ç»œé”™è¯¯", str(e)[:50]

        except Exception as e:
            return title, "âŒ æœªçŸ¥é”™è¯¯", str(e)[:50]

    return title, "âŒ å¤±è´¥", "è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°"


def main():
    """ä¸»å‡½æ•°"""
    # æ–‡ä»¶è·¯å¾„
    json_file = Path(__file__).parent.parent / 'task05_wechat' / 'wechat_articles_2025-11-29.json'
    failed_file = Path(__file__).parent / 'articles' / 'failed_articles.json'
    output_dir = Path(__file__).parent / 'articles'

    # è¯»å–åŸå§‹æ–‡ç« åˆ—è¡¨
    print("ğŸ“– è¯»å–åŸå§‹æ–‡ç« åˆ—è¡¨...")
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    articles = data.get('articles', [])

    # è¯»å–å¤±è´¥æ–‡ç« åˆ—è¡¨
    print("ğŸ“‹ è¯»å–å¤±è´¥æ–‡ç« åˆ—è¡¨...")
    with open(failed_file, 'r', encoding='utf-8') as f:
        failed_articles = json.load(f)

    total = len(failed_articles)
    print(f"ğŸ” å…±éœ€æ ¸æŸ¥ {total} ç¯‡å¤±è´¥æ–‡ç« ")

    # åˆ†ç±»ç»Ÿè®¡
    timeout_count = sum(1 for item in failed_articles if 'timeout' in item['error'].lower())
    deleted_count = total - timeout_count

    print(f"   - ç½‘ç»œè¶…æ—¶: {timeout_count} ç¯‡")
    print(f"   - å·²åˆ é™¤/è¿è§„: {deleted_count} ç¯‡")
    print(f"\nğŸš€ ä½¿ç”¨ 10 çº¿ç¨‹å¹¶å‘æ ¸æŸ¥...\n")

    # ç»“æœç»Ÿè®¡
    results = {
        "retry_success": [],
        "already_exists": [],
        "deleted": [],
        "timeout": [],
        "other_error": []
    }

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ ¸æŸ¥
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = {
            executor.submit(check_article, item, articles, output_dir): item
            for item in failed_articles
        }

        with tqdm(total=total, desc="æ ¸æŸ¥è¿›åº¦", unit="ç¯‡") as pbar:
            for future in as_completed(futures):
                item = futures[future]
                try:
                    title, status, detail = future.result()

                    # åˆ†ç±»ç»Ÿè®¡
                    if "é‡è¯•æˆåŠŸ" in status:
                        results["retry_success"].append({
                            "index": item['index'],
                            "title": title,
                            "detail": detail
                        })
                    elif "å·²å­˜åœ¨" in status:
                        results["already_exists"].append({
                            "index": item['index'],
                            "title": title
                        })
                    elif "åˆ é™¤" in status or "è¿è§„" in status or "æŠ•è¯‰" in status:
                        results["deleted"].append({
                            "index": item['index'],
                            "title": title,
                            "reason": detail
                        })
                    elif "è¶…æ—¶" in status:
                        results["timeout"].append({
                            "index": item['index'],
                            "title": title,
                            "detail": detail
                        })
                    else:
                        results["other_error"].append({
                            "index": item['index'],
                            "title": title,
                            "error": detail
                        })

                    pbar.set_postfix_str(f"{status}: {title[:30]}...")

                except Exception as e:
                    results["other_error"].append({
                        "index": item['index'],
                        "title": item['title'],
                        "error": str(e)
                    })

                pbar.update(1)

    # æ‰“å°è¯¦ç»†ç»Ÿè®¡
    print(f"\n{'='*70}")
    print("ğŸ“Š æ ¸æŸ¥ç»“æœç»Ÿè®¡\n")

    print(f"âœ… é‡è¯•æˆåŠŸ: {len(results['retry_success'])} ç¯‡")
    for item in results['retry_success']:
        print(f"   [{item['index']:04d}] {item['title'][:40]} - {item['detail']}")

    print(f"\nğŸ“ å·²å­˜åœ¨æ–‡ä»¶: {len(results['already_exists'])} ç¯‡")
    for item in results['already_exists']:
        print(f"   [{item['index']:04d}] {item['title'][:40]}")

    print(f"\nğŸ—‘ï¸  ç¡®è®¤å·²åˆ é™¤/è¿è§„: {len(results['deleted'])} ç¯‡")
    for item in results['deleted'][:10]:
        print(f"   [{item['index']:04d}] {item['title'][:40]} - {item['reason']}")
    if len(results['deleted']) > 10:
        print(f"   ... è¿˜æœ‰ {len(results['deleted']) - 10} ç¯‡")

    print(f"\nâ±ï¸  ä»ç„¶è¶…æ—¶: {len(results['timeout'])} ç¯‡")
    for item in results['timeout']:
        print(f"   [{item['index']:04d}] {item['title'][:40]} - {item['detail']}")

    print(f"\nâŒ å…¶ä»–é”™è¯¯: {len(results['other_error'])} ç¯‡")
    for item in results['other_error']:
        print(f"   [{item['index']:04d}] {item['title'][:40]} - {item['error']}")

    # ä¿å­˜è¯¦ç»†ç»“æœ
    result_file = output_dir / 'retry_results.json'
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\n{'='*70}")
    print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")

    # æ›´æ–°å¤±è´¥åˆ—è¡¨
    still_failed = results['deleted'] + results['timeout'] + results['other_error']
    if still_failed:
        with open(failed_file, 'w', encoding='utf-8') as f:
            failed_data = [
                {
                    "index": item['index'],
                    "title": item['title'],
                    "error": item.get('reason') or item.get('detail') or item.get('error', 'æœªçŸ¥é”™è¯¯')
                }
                for item in still_failed
            ]
            json.dump(failed_data, f, ensure_ascii=False, indent=2)

        print(f"ğŸ”„ æ›´æ–°åçš„å¤±è´¥åˆ—è¡¨: {len(still_failed)} ç¯‡")
    else:
        print(f"ğŸ‰ æ‰€æœ‰æ–‡ç« æ ¸æŸ¥å®Œæˆ,æ— å¤±è´¥æ–‡ç« !")

    # æœ€ç»ˆç»Ÿè®¡
    final_success = len(results['retry_success']) + len(results['already_exists'])
    print(f"\nâœ¨ æœ€ç»ˆæˆåŠŸ: {final_success}/{total} ç¯‡")
    print(f"âŒ æœ€ç»ˆå¤±è´¥: {len(still_failed)}/{total} ç¯‡")


if __name__ == '__main__':
    main()
