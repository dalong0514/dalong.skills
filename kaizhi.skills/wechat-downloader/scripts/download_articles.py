#!/usr/bin/env python3
# /// script
# requires-python = ">=3.11"
# dependencies = [
#     "requests",
#     "tqdm",
# ]
# ///

"""
å¾®ä¿¡å…¬ä¼—å·æ–‡ç« å¹¶è¡Œä¸‹è½½è„šæœ¬ï¼ˆä¼˜åŒ–ç‰ˆï¼‰

ä¼˜åŒ–ç‚¹ï¼š
1. å¢åŠ çº¿ç¨‹æ•°åˆ° 20
2. ä½¿ç”¨ä¼šè¯å¯¹è±¡å¤ç”¨è¿æ¥
3. å‡å°‘è¶…æ—¶æ—¶é—´
4. æ·»åŠ å¤±è´¥é‡è¯•æœºåˆ¶
5. å¿«é€Ÿå¤±è´¥ç­–ç•¥
"""

import json
import os
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Dict, List, Tuple
from urllib.parse import urlparse

import requests
from tqdm import tqdm


# å…¨å±€ä¼šè¯å¯¹è±¡ï¼Œæ”¯æŒè¿æ¥æ± å¤ç”¨
session = requests.Session()
session.mount('https://', requests.adapters.HTTPAdapter(
    pool_connections=20,
    pool_maxsize=20,
    max_retries=2
))


def sanitize_filename(filename: str, max_length: int = 100) -> str:
    """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    filename = filename.strip()
    if len(filename) > max_length:
        filename = filename[:max_length]
    return filename


def download_article(article: Dict, output_dir: Path, index: int, max_retries: int = 2) -> Tuple[bool, str, str]:
    """
    ä¸‹è½½å•ç¯‡æ–‡ç« ï¼ˆä¼˜åŒ–ç‰ˆï¼‰

    Args:
        article: æ–‡ç« ä¿¡æ¯å­—å…¸
        output_dir: è¾“å‡ºç›®å½•
        index: æ–‡ç« ç¼–å·
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

    Returns:
        (æ˜¯å¦æˆåŠŸ, æ–‡ç« æ ‡é¢˜, é”™è¯¯ä¿¡æ¯)
    """
    title = article.get('title', f'æœªå‘½åæ–‡ç« _{index}')
    url = article.get('content_url') or article.get('url')

    if not url:
        return False, title, "ç¼ºå°‘URL"

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    safe_title = sanitize_filename(title)
    filename = f"{index:04d}_{safe_title}.html"
    filepath = output_dir / filename

    if filepath.exists():
        return True, title, ""  # è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶

    # è®¾ç½®è¯·æ±‚å¤´
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Connection': 'keep-alive',
    }

    # é‡è¯•é€»è¾‘
    for attempt in range(max_retries):
        try:
            # ä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶æ—¶é—´
            response = session.get(url, headers=headers, timeout=15)
            response.raise_for_status()

            # å¿«é€Ÿæ£€æŸ¥æ˜¯å¦æ˜¯è¢«åˆ é™¤çš„æ–‡ç« 
            content = response.text
            if 'æ­¤å†…å®¹å› è¿è§„æ— æ³•æŸ¥çœ‹' in content or 'è¯¥å†…å®¹å·²è¢«å‘å¸ƒè€…åˆ é™¤' in content:
                return False, title, "æ–‡ç« å·²åˆ é™¤æˆ–è¿è§„"

            # ä¿å­˜æ–‡ç« 
            metadata = f"""<!--
æ–‡ç« æ ‡é¢˜: {title}
æ–‡ç« URL: {url}
ä¸‹è½½æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
-->
"""
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(metadata + content)

            return True, title, ""

        except requests.exceptions.Timeout:
            if attempt < max_retries - 1:
                time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿåé‡è¯•
                continue
            return False, title, "è¯·æ±‚è¶…æ—¶"

        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                time.sleep(0.5)
                continue
            return False, title, f"ç½‘ç»œé”™è¯¯: {str(e)}"

        except Exception as e:
            return False, title, f"æœªçŸ¥é”™è¯¯: {str(e)}"

    return False, title, "è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°"


def main():
    """ä¸»å‡½æ•°"""
    # æ–‡ä»¶è·¯å¾„
    json_file = Path(__file__).parent.parent / 'task05_wechat' / 'wechat_articles_2025-11-29.json'
    output_dir = Path(__file__).parent / 'articles'

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(exist_ok=True)

    # è¯»å– JSON æ–‡ä»¶
    print(f"ğŸ“– è¯»å–æ–‡ç« åˆ—è¡¨: {json_file}")
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    articles = data.get('articles', [])
    total_count = len(articles)

    print(f"ğŸ“Š å…±æ‰¾åˆ° {total_count} ç¯‡æ–‡ç« ")
    print(f"ğŸ’¾ ä¿å­˜ç›®å½•: {output_dir}")
    print(f"ğŸš€ ä½¿ç”¨ 20 çº¿ç¨‹å¹¶è¡Œä¸‹è½½ï¼ˆä¼˜åŒ–ç‰ˆï¼‰...\n")

    # ç»Ÿè®¡ä¿¡æ¯
    success_count = 0
    failed_count = 0
    failed_articles = []

    start_time = time.time()

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œä¸‹è½½ï¼ˆå¢åŠ åˆ° 20 çº¿ç¨‹ï¼‰
    with ThreadPoolExecutor(max_workers=20) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = {
            executor.submit(download_article, article, output_dir, idx + 1): (idx + 1, article)
            for idx, article in enumerate(articles)
        }

        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
        with tqdm(total=total_count, desc="ä¸‹è½½è¿›åº¦", unit="ç¯‡",
                  bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pbar:

            for future in as_completed(futures):
                idx, article = futures[future]
                try:
                    success, title, error_msg = future.result()

                    if success:
                        success_count += 1
                    else:
                        failed_count += 1
                        failed_articles.append({
                            'index': idx,
                            'title': title,
                            'error': error_msg
                        })

                except Exception as e:
                    failed_count += 1
                    failed_articles.append({
                        'index': idx,
                        'title': article.get('title', 'æœªçŸ¥'),
                        'error': str(e)
                    })

                pbar.update(1)
                # å®æ—¶æ›´æ–°æˆåŠŸç‡
                current_total = success_count + failed_count
                if current_total > 0:
                    success_rate = success_count / current_total * 100
                    pbar.set_postfix_str(f"æˆåŠŸç‡: {success_rate:.1f}%")

    elapsed_time = time.time() - start_time

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'='*60}")
    print(f"âœ… ä¸‹è½½æˆåŠŸ: {success_count} ç¯‡")
    print(f"âŒ ä¸‹è½½å¤±è´¥: {failed_count} ç¯‡")
    print(f"ğŸ“Š æˆåŠŸç‡: {success_count/total_count*100:.1f}%")
    print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.1f} ç§’")
    print(f"âš¡ å¹³å‡é€Ÿåº¦: {total_count/elapsed_time:.1f} ç¯‡/ç§’")

    # ä¿å­˜å¤±è´¥åˆ—è¡¨
    if failed_articles:
        print(f"\n{'='*60}")
        print("å¤±è´¥æ–‡ç« åˆ—è¡¨:")
        failed_file = output_dir / 'failed_articles.json'
        with open(failed_file, 'w', encoding='utf-8') as f:
            json.dump(failed_articles, f, ensure_ascii=False, indent=2)

        print(f"è¯¦ç»†ä¿¡æ¯å·²ä¿å­˜åˆ°: {failed_file}")

        # æ˜¾ç¤ºå‰ 10 ä¸ªå¤±è´¥çš„æ–‡ç« 
        for item in failed_articles[:10]:
            print(f"  [{item['index']:04d}] {item['title'][:40]} - {item['error']}")

        if len(failed_articles) > 10:
            print(f"  ... è¿˜æœ‰ {len(failed_articles) - 10} ç¯‡å¤±è´¥æ–‡ç« ")

    print(f"\n{'='*60}")
    print(f"ğŸ‰ ä¸‹è½½å®Œæˆï¼æ–‡ç« ä¿å­˜åœ¨: {output_dir}")


if __name__ == '__main__':
    main()
